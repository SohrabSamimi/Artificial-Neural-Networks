{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ANN August 4th.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SohrabSamimi/Artificial-Neural-Networks/blob/master/ANN_August_4th.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytTT17zrwMAu",
        "colab_type": "text"
      },
      "source": [
        "# Artificial Neural Networks DSTI Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6DymOXawMAw",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the Scikit Learn Digits dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbIh5AQ1wMAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZDfaDrzzzNT",
        "colab_type": "text"
      },
      "source": [
        "We import a few packages and then we import the load_digits dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2capCrsuwMA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8eca681-a2e1-4faf-98ae-ea6825da757f"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "digits=load_digits()\n",
        "print(digits.data.shape,digits.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 64) (1797,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9umeOXzCSf",
        "colab_type": "text"
      },
      "source": [
        "We see that the load_digits dataset contains 1797 samples(the images) each of them having 64 features.We confirm that the number of target values matches the number of samples by looking at the target's shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE-mhwqsy60L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeXWq5v8wMA6",
        "colab_type": "text"
      },
      "source": [
        "Let us display a few images from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om8vn609wMA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "b97f7c52-5ee6-43f4-9a01-4622e4b09fb3"
      },
      "source": [
        "fig, ax = plt.subplots(3, 5)\n",
        "ax.flatten()\n",
        "for i, axes in enumerate(ax.flat):\n",
        "    axes.imshow(digits.images[i], cmap='bone')\n",
        "    axes.set(xticks=[], yticks=[],\n",
        "            xlabel=digits.target_names[digits.target[i]])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 15 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZMpHBaLwMA-",
        "colab_type": "text"
      },
      "source": [
        "Now,we make training set,testing set,and we make predictions on the test set Xtest.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSRNq1clyYhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbIxLCcDwMA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "37513780-ae15-4f92-b843-e63b2f9910e1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "X,y=digits.data,digits.target\n",
        "Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,random_state=43)\n",
        "clf.fit(X,y)\n",
        "yfit=clf.predict(Xtest)\n",
        "yfit"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 8, 3, 8, 6, 0, 6, 5, 1, 1, 7, 1, 3, 9, 2, 6, 0, 4, 7, 4, 7, 0,\n",
              "       0, 8, 5, 0, 8, 2, 3, 3, 8, 6, 9, 8, 0, 7, 6, 9, 4, 8, 9, 6, 4, 0,\n",
              "       4, 6, 4, 4, 6, 0, 5, 0, 5, 4, 5, 9, 7, 5, 7, 4, 4, 6, 4, 6, 5, 4,\n",
              "       1, 5, 6, 4, 7, 4, 2, 6, 7, 4, 0, 4, 0, 8, 8, 0, 3, 5, 9, 6, 0, 5,\n",
              "       3, 0, 0, 4, 6, 9, 6, 6, 9, 4, 6, 9, 3, 7, 8, 9, 7, 0, 3, 3, 6, 7,\n",
              "       5, 2, 1, 9, 7, 7, 7, 7, 7, 0, 9, 2, 5, 7, 7, 4, 8, 3, 2, 6, 8, 0,\n",
              "       1, 6, 4, 4, 8, 0, 9, 0, 1, 6, 1, 7, 3, 2, 0, 5, 0, 7, 8, 9, 6, 0,\n",
              "       1, 5, 7, 1, 0, 7, 4, 1, 7, 9, 8, 2, 6, 4, 9, 7, 7, 5, 8, 0, 2, 9,\n",
              "       5, 6, 4, 5, 4, 2, 9, 6, 4, 1, 8, 7, 8, 7, 2, 6, 1, 6, 1, 4, 2, 6,\n",
              "       1, 8, 3, 6, 9, 0, 8, 2, 9, 4, 7, 9, 8, 4, 5, 2, 1, 4, 1, 8, 6, 2,\n",
              "       9, 8, 1, 8, 1, 5, 2, 8, 8, 5, 9, 2, 9, 2, 9, 2, 1, 8, 8, 9, 6, 8,\n",
              "       3, 1, 0, 3, 1, 1, 5, 4, 7, 6, 2, 4, 6, 4, 9, 9, 2, 0, 6, 5, 6, 0,\n",
              "       3, 7, 5, 0, 0, 3, 4, 5, 8, 9, 2, 1, 6, 7, 9, 6, 9, 3, 3, 7, 4, 3,\n",
              "       5, 8, 9, 4, 0, 0, 9, 1, 4, 0, 4, 3, 7, 6, 3, 0, 3, 8, 0, 4, 8, 8,\n",
              "       5, 3, 1, 2, 8, 0, 0, 3, 6, 8, 1, 7, 5, 8, 7, 2, 0, 4, 1, 7, 3, 8,\n",
              "       0, 4, 1, 1, 5, 5, 2, 8, 9, 9, 0, 4, 8, 8, 6, 8, 9, 4, 9, 7, 7, 7,\n",
              "       9, 6, 8, 7, 0, 4, 5, 1, 2, 4, 7, 5, 2, 3, 2, 5, 6, 6, 5, 6, 3, 0,\n",
              "       9, 8, 8, 3, 4, 2, 7, 9, 4, 8, 6, 8, 7, 6, 2, 1, 9, 2, 2, 8, 1, 2,\n",
              "       1, 9, 5, 4, 6, 2, 3, 3, 8, 0, 0, 5, 9, 2, 7, 5, 5, 9, 6, 5, 5, 0,\n",
              "       8, 5, 9, 9, 7, 1, 4, 6, 4, 0, 7, 0, 5, 6, 5, 0, 8, 2, 6, 9, 0, 5,\n",
              "       0, 3, 2, 8, 8, 8, 2, 6, 1, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTjBsykR1FAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d5c9db9-0bd8-409b-91be-0265d6abb0ed"
      },
      "source": [
        "Xtrain[0].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG805MTH5iNG",
        "colab_type": "text"
      },
      "source": [
        "The following code creates a matrix called \"y_multilabel\" composed of two labels for each image: the first label indicates if the value is above 7 and the second indicates if the value is odd.Then we train an instance of KNeighborsClassifier on the 'multilabeled' matrix.We can then perform a prediction and we notice we obtain two labels('False' and 'True'): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKloILl7yiJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66a5159b-f157-4b13-a3af-4dd5b05b8f08"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "ytrain_large=(ytrain>=7)\n",
        "ytrain_odd=(ytrain %2 == 1)\n",
        "y_multilabel = np.c_[ytrain_large, ytrain_odd]\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(Xtrain,y_multilabel)\n",
        "prediction = knn_clf.predict(Xtest)\n",
        "print(prediction)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False  True]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [ True  True]\n",
            " [False  True]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [ True  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [False  True]\n",
            " [False False]\n",
            " [ True False]\n",
            " [ True False]\n",
            " [ True False]\n",
            " [False False]\n",
            " [False False]\n",
            " [False  True]\n",
            " [ True  True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMRk3EWu8ObZ",
        "colab_type": "text"
      },
      "source": [
        "Let us now check that the predictions are correct by comparing KNeighborsClassifier predictions to the previous predictions using SVM:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL042xUr7_L1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adae5dcd-6de6-46d6-c3be-b7fd7fe19ff3"
      },
      "source": [
        "print((yfit>=7)==prediction[:,0])\n",
        "print((yfit%2 == 1) == prediction[:,1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True False  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True]\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True False  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True False  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XnL1Y-c8iSD",
        "colab_type": "text"
      },
      "source": [
        "# We see two arrays:\n",
        "\n",
        "1.   The first array returns True if both predictions(SVM and KNeigborsCLassifier) return a number greater or equal to 7\n",
        "2.   The second array returns True if both predictions return an odd number\n",
        "\n",
        "\n",
        "### We notice there are very few errors.\n",
        "Of course this does not mean the two methods predicted the same numbers: for instance it could happen that SVM predicts 9 and KNeighborsClassifier predicts 7,so we would get a True value,but the probability that we are ***always*** right is very low.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vmUr6qwCbje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e77664fe-551e-486b-96f9-e0c657db9b21"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import f1_score\n",
        "ytrain_knn_pred=cross_val_predict(knn_clf,Xtrain,y_multilabel,cv = 4)\n",
        "f1_score(y_multilabel,ytrain_knn_pred,average=\"macro\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98409515752453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XloxPWcZ-TMj",
        "colab_type": "text"
      },
      "source": [
        "# Now we create a confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUXY972SwMBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion=confusion_matrix(ytest,yfit)\n",
        "confusion_df=pd.DataFrame(confusion,index=range(10),columns=range(10))\n",
        "\n",
        "axes=sns.heatmap(confusion_df,annot=True,cmap='nipy_spectral_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQAhOqVE0RkS",
        "colab_type": "text"
      },
      "source": [
        "A confusion matrix which is close to a diagonal matrix represents an accurate model.The confusion matrix above shows us that there was only one mistake in the predictions.One sample representing the number 9 was mistakenly predicted as being number 7.Otherwise everything is correct.The model is thus pretty accurate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVT838Tb1nRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgG-ys_C1m5k",
        "colab_type": "text"
      },
      "source": [
        "We now show a set of points representing clusters,each of them having a  center represented as a red cross."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsMh_WTSwMBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import scale\n",
        "X_digits, y_digits = load_digits(return_X_y=True)\n",
        "data = scale(X_digits)\n",
        "kmeans = KMeans(init='k-means++', n_clusters=10, n_init=10)\n",
        "pca=PCA(n_components=10).fit_transform(data)\n",
        "reduced_data = PCA(n_components=2).fit_transform(data)\n",
        "kmeans.fit(reduced_data)\n",
        "plt.scatter(reduced_data[:,0],reduced_data[:,1],color='black')\n",
        "centroids=kmeans.cluster_centers_\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "            marker='x', s=169, linewidths=3,\n",
        "            color='r', zorder=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsvB22bYwMBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tp8aTrSwMBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_digits, y_digits = load_digits(return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TGmLSf_wMBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "X_digits, y_digits = load_digits(return_X_y=True)\n",
        "data = scale(X_digits)\n",
        "reduced_data = PCA(n_components=2).fit_transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkArTP3awMBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "polyn = PolynomialFeatures(degree=2)\n",
        "x_ = polyn.fit_transform(X_digits) \n",
        "   \n",
        "clf = LinearRegression()\n",
        "clf.fit(x_,y_digits)\n",
        "y1 = clf.predict(x_)  \n",
        "y1\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUPhCinKP69p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANU4j_VwMBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "X = load_digits().data\n",
        "y=load_digits().target\n",
        "X.shape\n",
        "\n",
        "embedding = LocallyLinearEmbedding(n_components=2)\n",
        "X_transformed = embedding.fit_transform(X[:50])\n",
        "X_transformed.shape\n",
        "plt.scatter(X_transformed[:,0],X_transformed[:,1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QULQl3tT616",
        "colab_type": "text"
      },
      "source": [
        "We are now going to do a Polynomial Regression of degree 4 on the X_transformed data we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZDdtY1NT48q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8rfAZKumzZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=X_transformed[:,0].reshape(-1,1)\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_features=PolynomialFeatures(degree=4,include_bias=False)\n",
        "X_poly=poly_features.fit_transform(X)\n",
        "X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ZeOrCKWGWF",
        "colab_type": "text"
      },
      "source": [
        "X_poly now contains the feature of X the powers of X up to degree 4,and the trick is now to perform a Linear Regression to this extended data.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIuZhgrQWm2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_reg=LinearRegression()\n",
        "a=lin_reg.fit(X_poly,X_transformed[:,1].reshape(-1,1))\n",
        "b=lin_reg.intercept_,lin_reg.coef_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw_bPeMYWrpe",
        "colab_type": "text"
      },
      "source": [
        "We now plot our polynomial function of degree 4 and our data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heKpH_PYS_Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.linspace(-0.4,0.3)\n",
        "plt.plot(x,-95.99*x**4-16.49*x**3+10*x**2+0.98*x-0.11,color='green')\n",
        "plt.scatter(X_transformed[:,0],X_transformed[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80znqOrwV7VJ",
        "colab_type": "text"
      },
      "source": [
        "Polynomial Regression of degree 4 seems to fit our data very well without overfitting!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arr8-F78N1Sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "972PVd_sYQQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C=1.0\n",
        "\n",
        "svc1 = svm.SVR(kernel='rbf', C=C).fit(X_transformed[:,0].reshape(-1,1),X_transformed[:,1] )\n",
        "\n",
        "h=0.02\n",
        "x_min, x_max = X_transformed[:, 0].min() - 1, X_transformed[:, 0].max() + 1\n",
        "y_min, y_max = X_transformed[:, 1].min() - 1, X_transformed[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
        "for i, clf in enumerate((svc1,svc1)):\n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
        "    Z = clf.predict(np.c_[xx.ravel()].reshape(-1,1))\n",
        "    Z = Z.reshape((122,127))\n",
        "    # Put the result into a color plot\n",
        "    \n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "\n",
        "    # Plot also the training points\n",
        "    plt.scatter(xx, yy, c=y, cmap=plt.cm.coolwarm)\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faFg-8SSwMBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense,Dropout,Flatten\n",
        "from keras.layers import MaxPooling2D,Conv2D\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVKaFUvcwMBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d0KRe-wDsIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize=(64,64)\n",
        "Xtrain_resized = [cv2.resize(img, resize) for img in Xtrain]\n",
        "Xtest_resized = [cv2.resize(img, resize) for img in Xtest]\n",
        "Xtrain_resized = np.array(Xtrain_resized).astype('float32')\n",
        "Xtrain_resized /= 255\n",
        "\n",
        "Xtest_resized = np.array(Xtest_resized).astype('float32')\n",
        "Xtest_resized /= 255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeBFqnReEqkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4zVkmJ3EXy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain_cat = keras.utils.to_categorical(ytrain, num_classes)\n",
        "ytest_cat = keras.utils.to_categorical(ytest, num_classes)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgmvDmKhFtrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain_resized=Xtrain_resized.reshape(Xtrain_resized.shape[0],64,64,1)\n",
        "input_shape = Xtrain_resized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmpYkvUGEt9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#  first convolutional layer\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape= input_shape))\n",
        "\n",
        "#  second convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "#  max pooling layer \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#  dropout layer\n",
        "model.add(Dropout(0.125))\n",
        "\n",
        "#  flatten layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#  dense layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "#   dropout layer\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#  dense layer\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,  optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO38_BH2nrLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "model.fit(Xtrain_resized, ytrain_cat, \n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs, \n",
        "          verbose=1, \n",
        "          validation_data=(Xtest_resized, ytest_cat))\n",
        "accuracy = model.evaluate(Xtest_resized, ytest_cat, verbose=0)\n",
        "print('Test accuracy:', accuracy[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}